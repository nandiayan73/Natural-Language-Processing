{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An RNN, or Recurrent Neural Network, is a type of artificial neural network designed for processing sequences of data. Unlike feedforward neural networks, which process data in a fixed, one-way direction, RNNs have loops that allow them to maintain a hidden state representing information about previous inputs in the sequence. This makes RNNs well-suited for tasks involving sequential data, such as natural language processing, speech recognition, and time series analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An RNN, or Recurrent Neural Network, is a type of artificial neural network designed for processing sequences of data. Unlike feedforward neural networks, which process data in a fixed, one-way direction, RNNs have loops that allow them to maintain a hidden state representing information about previous inputs in the sequence. This makes RNNs well-suited for tasks involving sequential data, such as natural language processing, speech recognition, and time series analysis.\n",
    "\n",
    "In an RNN, each step in the sequence is processed, and the hidden state from the previous step is used as part of the input for the current step. This allows RNNs to capture dependencies and patterns in sequential data, which can be important for tasks like predicting the next word in a sentence or analyzing the trends in a time series.\n",
    "\n",
    "However, traditional RNNs have some limitations, such as the vanishing gradient problem, which can make it challenging to capture long-term dependencies. As a result, more advanced RNN architectures like Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) have been developed to address these issues and improve the performance of sequence-based tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN Output:\n",
      "tf.Tensor([[-0.19778715 -0.44980606  0.9631618  -0.43429807]], shape=(1, 4), dtype=float32)\n",
      "Final RNN State:\n",
      "tf.Tensor([[-0.19778715 -0.44980606  0.9631618  -0.43429807]], shape=(1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the RNN model\n",
    "input_dim = 3  # Dimension of the input sequence\n",
    "hidden_dim = 4  # Dimension of the hidden state\n",
    "sequence_length = 5  # Length of the sequence\n",
    "batch_size = 1\n",
    "\n",
    "# Generate some example input data (you can replace this with your own data)\n",
    "input_sequence = np.random.randn(batch_size, sequence_length, input_dim)\n",
    "\n",
    "# Define the RNN cell\n",
    "cell = tf.keras.layers.SimpleRNN(hidden_dim, return_state=True)\n",
    "\n",
    "# Initialize the initial state of the RNN\n",
    "initial_state = [tf.zeros((batch_size, hidden_dim))]\n",
    "\n",
    "# Run the RNN\n",
    "outputs, final_state = cell(input_sequence, initial_state)\n",
    "\n",
    "# Print the output and final state\n",
    "print(\"RNN Output:\")\n",
    "print(outputs)\n",
    "\n",
    "print(\"Final RNN State:\")\n",
    "print(final_state)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
