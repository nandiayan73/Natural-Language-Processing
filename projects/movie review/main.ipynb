{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                             review\n",
      "0   neg  how do films like mouse hunt get into theatres...\n",
      "1   neg  some talented actresses are blessed with a dem...\n",
      "2   pos  this has been an extraordinary year for austra...\n",
      "3   pos  according to hollywood movies made in last few...\n",
      "4   neg  my first press screening of 1998 and already i...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "review    35\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc=pd.read_csv(\"moviereviews.tsv\",sep=\"\\t\")\n",
    "print(doc.head())\n",
    "doc.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1965"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)\n",
    "doc.dropna(inplace=True)\n",
    "len(doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting the empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1938"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blanks=[]\n",
    "for i,lb,rv in doc.itertuples():\n",
    "    if type(rv)==str:\n",
    "        if rv.isspace():\n",
    "            blanks.append(i)\n",
    "doc.drop(blanks,inplace=True)\n",
    "len(doc)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting the data into datasets:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600     eight years after its release , disney has dec...\n",
      "931     it's been a long time since walt disney has de...\n",
      "937     richard gere can be a commanding actor , but h...\n",
      "1811    1 . he doesn't have a hard-to-decipher accent ...\n",
      "1512    when i arrived in paris in june , 1992 , i was...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x=doc['review']\n",
    "y=doc['label']\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.33,random_state=42)\n",
    "print(x_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'pos'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\CODING\\AIML\\Natural Language Processing\\projects\\movie review\\main.ipynb Cell 9\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CODING/AIML/Natural%20Language%20Processing/projects/movie%20review/main.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpipeline\u001b[39;00m \u001b[39mimport\u001b[39;00m Pipeline\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CODING/AIML/Natural%20Language%20Processing/projects/movie%20review/main.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m text_classifier\u001b[39m=\u001b[39mPipeline([(\u001b[39m'\u001b[39m\u001b[39mtfidf\u001b[39m\u001b[39m'\u001b[39m,TfidfVectorizer()),(\u001b[39m'\u001b[39m\u001b[39mrgr\u001b[39m\u001b[39m'\u001b[39m,LinearRegression())])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/CODING/AIML/Natural%20Language%20Processing/projects/movie%20review/main.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m text_classifier\u001b[39m.\u001b[39;49mfit(x_train,y_train)\n",
      "File \u001b[1;32mc:\\Users\\nandi.LAPTOP-6NVS0PRF\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nandi.LAPTOP-6NVS0PRF\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    419\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 420\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[0;32m    422\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nandi.LAPTOP-6NVS0PRF\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nandi.LAPTOP-6NVS0PRF\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:678\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    674\u001b[0m n_jobs_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs\n\u001b[0;32m    676\u001b[0m accept_sparse \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositive \u001b[39melse\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> 678\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    679\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse, y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m    680\u001b[0m )\n\u001b[0;32m    682\u001b[0m has_sw \u001b[39m=\u001b[39m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32mc:\\Users\\nandi.LAPTOP-6NVS0PRF\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\nandi.LAPTOP-6NVS0PRF\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1163\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[0;32m   1147\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[1;32m-> 1163\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39;49mmulti_output, y_numeric\u001b[39m=\u001b[39;49my_numeric, estimator\u001b[39m=\u001b[39;49mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1167\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\nandi.LAPTOP-6NVS0PRF\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1188\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     _ensure_no_complex_data(y)\n\u001b[0;32m   1187\u001b[0m \u001b[39mif\u001b[39;00m y_numeric \u001b[39mand\u001b[39;00m y\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mO\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 1188\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat64)\n\u001b[0;32m   1190\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'pos'"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_classifier=Pipeline([('tfidf',TfidfVectorizer()),('clf',LinearSVC())])\n",
    "text_classifier.fit(x_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg' 'pos' 'pos' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg'\n",
      " 'pos' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg'\n",
      " 'pos' 'pos' 'neg' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos'\n",
      " 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'pos'\n",
      " 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'pos'\n",
      " 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg' 'pos'\n",
      " 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg'\n",
      " 'neg' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos'\n",
      " 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'pos' 'neg' 'pos'\n",
      " 'pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg'\n",
      " 'neg' 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos'\n",
      " 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg'\n",
      " 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg'\n",
      " 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg'\n",
      " 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos'\n",
      " 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg'\n",
      " 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos'\n",
      " 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos'\n",
      " 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'neg'\n",
      " 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos'\n",
      " 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg'\n",
      " 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos'\n",
      " 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg' 'neg'\n",
      " 'neg' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg'\n",
      " 'neg' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'neg'\n",
      " 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'neg'\n",
      " 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg'\n",
      " 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos'\n",
      " 'pos' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg'\n",
      " 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'pos' 'neg' 'neg'\n",
      " 'neg' 'pos' 'pos' 'pos' 'neg' 'pos' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg'\n",
      " 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg'\n",
      " 'pos' 'pos' 'pos' 'pos' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos'\n",
      " 'neg' 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg'\n",
      " 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos'\n",
      " 'pos' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos'\n",
      " 'neg' 'neg' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg'\n",
      " 'pos' 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'pos'\n",
      " 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg'\n",
      " 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg'\n",
      " 'pos' 'neg' 'neg' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg' 'neg'\n",
      " 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg'\n",
      " 'pos' 'pos' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg'\n",
      " 'pos' 'neg' 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos'\n",
      " 'pos' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'pos' 'pos' 'neg'\n",
      " 'pos' 'neg' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'pos' 'pos' 'neg'\n",
      " 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg'\n",
      " 'neg' 'pos' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg'\n",
      " 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg'\n",
      " 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos'\n",
      " 'neg' 'pos' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'pos' 'neg'\n",
      " 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'pos' 'pos' 'neg'\n",
      " 'neg' 'pos' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'pos' 'pos' 'neg'\n",
      " 'neg' 'neg' 'neg' 'pos']\n"
     ]
    }
   ],
   "source": [
    "y_pred=text_classifier.predict(x_test)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.846875\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg']\n"
     ]
    }
   ],
   "source": [
    "print(text_classifier.predict([\"I can't believe it! Once again, we're treated to the uproarious antics of a fantastic ensemble cast. It had been so long since I indulged in the sheer joy of a refreshing and side-splitting Bollywood movie. Pankaj Tripathi, Varun Sharma, Pulkit Samrat, Richa Chaddha, and Manjot Singh, these maestros of comedy, have returned to deliver an unforgettable laughter-packed experience. \"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
