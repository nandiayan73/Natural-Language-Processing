{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Washington, DC - GPE - Countries, cities, states\n",
      "next May - DATE - Absolute or relative dates or periods\n",
      "the Washington Monument - ORG - Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "def show_ents(doc):\n",
    "    # print(type(doc.ents))\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))\n",
    "    else:\n",
    "        print('No named entities found.')\n",
    "doc=nlp(u\"May I go to Washington, DC next May to see the Washington Monument?\")\n",
    "# doc=nlp(u\"Radhe Radhe\")\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 - CARDINAL - Numerals that do not fall under another type\n",
      "Wipro - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
      "Tesla - ORG - Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(u\"Can I borrow 500 rupees from you for buying  Wipro. Tesla is gay\")\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating a new entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PashaBhai,)\n",
      "PashaBhai - GPE - Countries, cities, states\n",
      "nigga - PERSON - People, including fictional\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(u\"PashaBhai is looking for a peaceful nigga.\")\n",
    "PERSON=doc.vocab.strings[u'PERSON']\n",
    "# creating a new entity\n",
    "new_entity=Span(doc,6,7,label=PERSON)\n",
    "print(doc.ents)\n",
    "\n",
    "# appending the new entity to the entity list\n",
    "doc.ents=list(doc.ents)+[new_entity]\n",
    "\n",
    "show_ents(doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART-2: IDENTIFYIGN A SERIES OF WORDS-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first - ORDINAL - \"first\", \"second\", etc.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Our company plans to introduce a new vacuum cleaner. '\n",
    "          u'If successful, the vacuum-cleaner will be our first product, and a pizza.')\n",
    "\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "matcher=PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_list=['vacuum cleaner','vacuum-cleaner','pizza']\n",
    "phrase_patterns=[nlp(text) for text in phrase_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE NEED TO GET THE INDICES OF THE RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vacuum cleaner, vacuum-cleaner, pizza]\n",
      "vacuum cleaner\n",
      "vacuum-cleaner\n",
      "pizza\n"
     ]
    }
   ],
   "source": [
    "print(phrase_patterns)\n",
    "matcher.add('newproduct',phrase_patterns)\n",
    "matches=matcher(doc)\n",
    "# we search for the indices of the matches:\n",
    "for match in matches:\n",
    "    print(doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vacuum cleaner - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
      "vacuum-cleaner - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
      "first - ORDINAL - \"first\", \"second\", etc.\n",
      "pizza - PRODUCT - Objects, vehicles, foods, etc. (not services)\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "PROD=doc.vocab.strings[u\"PRODUCT\"]\n",
    "new_ents=[Span(doc,match[1],match[2],label=PROD) for match in matches]\n",
    "\n",
    "doc.ents=list(doc.ents)+new_ents\n",
    "\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the no of entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(u\"Originally priced at Rs 50,however for you the shirt costs rupees 20.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 - CARDINAL - Numerals that do not fall under another type\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_list=[\"Rs\",\"rupees\"]\n",
    "phrase_patterns=[nlp(text) for text in phrase_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('newCurrency',phrase_patterns)\n",
    "matches=matcher(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the span we define the text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rs - MONEY - Monetary values, including unit\n",
      "rupees - MONEY - Monetary values, including unit\n",
      "20 - CARDINAL - Numerals that do not fall under another type\n"
     ]
    }
   ],
   "source": [
    "MONEY=doc.vocab.strings[u\"MONEY\"]\n",
    "new_ents=[Span(doc,match[1],match[2],label=\"MONEY\") for match in matches]\n",
    "doc.ents=list(doc.ents)+new_ents\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for ent in doc.ents:\n",
    "    if(ent.label_=='MONEY'):\n",
    "        count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([ent for ent in doc.ents if ent.label_==\"MONEY\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
